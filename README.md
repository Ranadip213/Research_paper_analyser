# Research_Paper_analyser
Analyse a Research paper weather it is publishable or not
# Research_Paper_analyser
Analyse a Research paper weather it is publishable or not
Publishability Classification using BERT

This project uses BERT (Bidirectional Encoder Representations from Transformers) for classifying papers as Publishable or Non-Publishable based on their content. The BERT model is fine-tuned for sequence classification on a dataset of academic papers.

Project Overview

Objective: To classify papers as either publishable or non-publishable based on their content, and generate rationale for why the paper is considered publishable.
Tools:
BERT (via Hugging Face's transformers library)
TensorFlow for training the model
pandas for data manipulation
NumPy for numerical operations
Matplotlib for visualizing training results
Prerequisites

Before running the code, make sure to have the following libraries installed:

transformers
tensorflow
pandas
numpy
matplotlib
You can install the necessary dependencies using pip:

pip install transformers tensorflow pandas numpy matplotlib
Dataset

The dataset should have the following structure:

train.csv:
extracted_text: Contains the text extracted from academic papers.
label: Binary classification (0 for non-publishable, 1 for publishable).
test.csv:
extracted_text: Contains the text extracted from academic papers.
filename: Unique identifier for each paper (e.g., file name or paper ID).
extracted_text: Contains the extracted text of the papers.
Steps to Run the Project

Data Preprocessing:
The text data is preprocessed by tokenizing the papers and cleaning any unnecessary characters.
BERT requires tokenization before inputting data into the model.
Model Training:
The BERT model (bert-base-uncased) is fine-tuned for binary classification.
The model is trained using the training dataset for 3 epochs, with the Adam optimizer and Sparse Categorical Crossentropy loss function.
Prediction:
The model predicts whether a paper is publishable or non-publishable on the test dataset.
Rationale Generation:
For papers classified as publishable, a rationale is generated by extracting the first 50 characters from the paper text to generate a brief justification for the decision.
Output:
The results, including paper ID, classification (publishable/non-publishable), conference assignment, and rationale, are saved into a results.csv file.
Usage Instructions

Training the Model

Load the train.csv dataset
Fine-tune the BERT model for binary classification
Save the trained model
Generating Predictions

Load the test.csv dataset
Use the trained model to predict the publishability of papers
Generate rationales and save the results in results.csv
Evaluation

The model's performance can be evaluated by looking at the accuracy, F1 score, and a classification report generated from the test.csv dataset. These metrics are printed after evaluating the model.

Example Output (results.csv)

The output file results.csv will contain:

Paper ID	Publishable	Conference	Rationale
paper_001	1	cvpr	The paper's content aligns with the focus areas of the conference due to its strong emphasis on ...
paper_002	0	na	na
...	...	...	...
Important Notes

Ensure the training and test datasets are correctly formatted before running the model.
The generate_rationale function is a placeholder, and you can modify the logic for generating more detailed rationales based on the content.
